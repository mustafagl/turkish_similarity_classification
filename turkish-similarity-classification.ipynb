{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":6284327,"sourceType":"datasetVersion","datasetId":3613338},{"sourceId":6348521,"sourceType":"datasetVersion","datasetId":3611719},{"sourceId":6349833,"sourceType":"datasetVersion","datasetId":3614608}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Kütüphanelerin İmport Edilmesi\n\nBu bölümde, modelin eğitimi ve değerlendirilmesi için gerekli olan Python kütüphaneleri import edilir.\n","metadata":{}},{"cell_type":"code","source":"!pip install transformers","metadata":{"_uuid":"2f01bd75-8c5d-42a6-a3cc-8ba240b25344","_cell_guid":"92fe1149-cf87-4ce1-96ee-1209fde57348","execution":{"iopub.status.busy":"2024-03-11T13:17:35.594464Z","iopub.execute_input":"2024-03-11T13:17:35.594814Z","iopub.status.idle":"2024-03-11T13:17:39.881791Z","shell.execute_reply.started":"2024-03-11T13:17:35.594784Z","shell.execute_reply":"2024-03-11T13:17:39.880700Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.8/site-packages (4.38.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.8/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/site-packages (from transformers) (6.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/site-packages (from transformers) (23.1)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.8/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.8/site-packages (from transformers) (0.21.4)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.8/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/site-packages (from transformers) (4.65.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.7.1)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->transformers) (2023.5.7)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->transformers) (1.26.16)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install openpyxl --upgrade","metadata":{"_uuid":"b927127f-4d4f-477c-819f-33c7c4e60213","_cell_guid":"fbb83421-76d1-4a18-85e6-30990398ca39","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-11T13:17:39.883729Z","iopub.execute_input":"2024-03-11T13:17:39.884040Z","iopub.status.idle":"2024-03-11T13:17:59.172324Z","shell.execute_reply.started":"2024-03-11T13:17:39.884009Z","shell.execute_reply":"2024-03-11T13:17:59.171226Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: openpyxl in /usr/local/lib/python3.8/site-packages (3.1.2)\nRequirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/site-packages (from openpyxl) (1.1.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport transformers\nimport tensorflow as tf\n#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n#assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n#config = tf.config.experimental.set_memory_growth(physical_devices[0], True)","metadata":{"_uuid":"e1796b67-6467-4574-a3f8-580cfc34020e","_cell_guid":"513fcb85-076e-4841-a3d9-adb84314104e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-11T13:17:59.173526Z","iopub.execute_input":"2024-03-11T13:17:59.173779Z","iopub.status.idle":"2024-03-11T13:18:29.994667Z","shell.execute_reply.started":"2024-03-11T13:17:59.173753Z","shell.execute_reply":"2024-03-11T13:18:29.993792Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"D0311 13:18:25.860886829    3268 config.cc:119]                        gRPC EXPERIMENT tcp_frame_size_tuning               OFF (default:OFF)\nD0311 13:18:25.860913746    3268 config.cc:119]                        gRPC EXPERIMENT tcp_rcv_lowat                       OFF (default:OFF)\nD0311 13:18:25.860917581    3268 config.cc:119]                        gRPC EXPERIMENT peer_state_based_framing            OFF (default:OFF)\nD0311 13:18:25.860920781    3268 config.cc:119]                        gRPC EXPERIMENT flow_control_fixes                  ON  (default:ON)\nD0311 13:18:25.860923536    3268 config.cc:119]                        gRPC EXPERIMENT memory_pressure_controller          OFF (default:OFF)\nD0311 13:18:25.860926235    3268 config.cc:119]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size OFF (default:OFF)\nD0311 13:18:25.860929050    3268 config.cc:119]                        gRPC EXPERIMENT new_hpack_huffman_decoder           ON  (default:ON)\nD0311 13:18:25.860933491    3268 config.cc:119]                        gRPC EXPERIMENT event_engine_client                 OFF (default:OFF)\nD0311 13:18:25.860936320    3268 config.cc:119]                        gRPC EXPERIMENT monitoring_experiment               ON  (default:ON)\nD0311 13:18:25.860939096    3268 config.cc:119]                        gRPC EXPERIMENT promise_based_client_call           OFF (default:OFF)\nD0311 13:18:25.860941904    3268 config.cc:119]                        gRPC EXPERIMENT free_large_allocator                OFF (default:OFF)\nD0311 13:18:25.860944643    3268 config.cc:119]                        gRPC EXPERIMENT promise_based_server_call           OFF (default:OFF)\nD0311 13:18:25.860947617    3268 config.cc:119]                        gRPC EXPERIMENT transport_supplies_client_latency   OFF (default:OFF)\nD0311 13:18:25.860955592    3268 config.cc:119]                        gRPC EXPERIMENT event_engine_listener               OFF (default:OFF)\nI0311 13:18:25.861269192    3268 ev_epoll1_linux.cc:122]               grpc epoll fd: 58\nD0311 13:18:25.861284011    3268 ev_posix.cc:144]                      Using polling engine: epoll1\nD0311 13:18:25.861307622    3268 dns_resolver_ares.cc:822]             Using ares dns resolver\nD0311 13:18:25.861921832    3268 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD0311 13:18:25.861934083    3268 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD0311 13:18:25.861938349    3268 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD0311 13:18:25.861941535    3268 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD0311 13:18:25.861944548    3268 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD0311 13:18:25.861947680    3268 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin_experimental\"\nD0311 13:18:25.861955779    3268 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD0311 13:18:25.861978255    3268 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD0311 13:18:25.862021859    3268 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD0311 13:18:25.862040423    3268 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD0311 13:18:25.862044063    3268 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD0311 13:18:25.862047235    3268 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD0311 13:18:25.862054698    3268 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_resolver_experimental\"\nD0311 13:18:25.862058043    3268 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD0311 13:18:25.862061582    3268 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD0311 13:18:25.862066076    3268 certificate_provider_registry.cc:35]  registering certificate provider factory for \"file_watcher\"\nI0311 13:18:25.866424286    3268 socket_utils_common_posix.cc:408]     Disabling AF_INET6 sockets because ::1 is not available.\nI0311 13:18:25.881231656    3429 socket_utils_common_posix.cc:337]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE0311 13:18:25.886885804    3429 oauth2_credentials.cc:236]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {created_time:\"2024-03-11T13:18:25.886866712+00:00\", grpc_status:2}\n/usr/local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Veri Setinin Yüklenmesi ve Ön İşleme\n\nBu bölümde, veri seti yüklenir ve modelin eğitimi için uygun hale getirilir. Ön işleme adımları arasında veri temizleme, tokenizasyon ve vektörleştirme bulunabilir.\n","metadata":{}},{"cell_type":"code","source":"max_length = 128  # Maximum length of input sentence to the model.\nbatch_size = 200\nsteps_per_epoch = 60000 // batch_size\nepochs = 2","metadata":{"_uuid":"86780caa-ee00-415c-83f3-3e9d7bd96a5b","_cell_guid":"cd011deb-2d29-450c-96dd-0e87d5267bf9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-11T13:18:29.996569Z","iopub.execute_input":"2024-03-11T13:18:29.996985Z","iopub.status.idle":"2024-03-11T13:18:30.001036Z","shell.execute_reply.started":"2024-03-11T13:18:29.996944Z","shell.execute_reply":"2024-03-11T13:18:30.000272Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndata1 = pd.read_excel('/kaggle/input/snli-turkish/snli_turkish.xlsx')  \ndata2 = pd.read_excel('/kaggle/input/snli-turkish/snli_turkish1.xlsx')  \ndata3 = pd.read_excel('/kaggle/input/snli-turkish/snli_turkish2.xlsx')  \ndata4 = pd.read_excel('/kaggle/input/snli-turkish/snli_turkish3.xlsx')  \ndata5 = pd.read_excel('/kaggle/input/snli-turkish/snli_turkish4.xlsx')  \nreal_data  = pd.read_excel('/kaggle/input/snli-turkish/log_df.xlsx')\n\nlabels = [\"contradiction\", \"entailment\", \"neutral\"]","metadata":{"_uuid":"6ad5c9c2-7212-4005-acd8-e6a012f64a62","_cell_guid":"a1d09277-8a47-4a9f-9f81-1f9fb000f90e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-11T13:18:30.002002Z","iopub.execute_input":"2024-03-11T13:18:30.002238Z","iopub.status.idle":"2024-03-11T13:19:12.619734Z","shell.execute_reply.started":"2024-03-11T13:18:30.002217Z","shell.execute_reply":"2024-03-11T13:19:12.618939Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"real_data.columns = [\"Öncül\",\" hipotez\",\" etiket\"]\n\nfor col in data5.columns:\n    print(col)","metadata":{"_uuid":"917c1247-5258-452c-a472-7bf47595a086","_cell_guid":"f626a735-7a12-4030-b996-8141aac069bb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-11T13:19:12.620777Z","iopub.execute_input":"2024-03-11T13:19:12.621051Z","iopub.status.idle":"2024-03-11T13:19:12.625748Z","shell.execute_reply.started":"2024-03-11T13:19:12.621027Z","shell.execute_reply":"2024-03-11T13:19:12.625013Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Öncül\n hipotez\n etiket\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.concat([data1, data2, data3, data4, data5, real_data],ignore_index=True)","metadata":{"_uuid":"b6704c42-7250-4c37-9d50-1bb7b3ecff09","_cell_guid":"5a1477cf-04d9-4750-a4f9-db2ba6612cb4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-11T13:19:12.626685Z","iopub.execute_input":"2024-03-11T13:19:12.626933Z","iopub.status.idle":"2024-03-11T13:19:12.660481Z","shell.execute_reply.started":"2024-03-11T13:19:12.626911Z","shell.execute_reply":"2024-03-11T13:19:12.659729Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"display(data[500000:])","metadata":{"_uuid":"70486218-fd41-4a74-ae4d-8b3acf50cd5c","_cell_guid":"2d8f8b88-e92e-47b9-aa7c-838102bbbc30","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-11T13:19:12.661576Z","iopub.execute_input":"2024-03-11T13:19:12.661842Z","iopub.status.idle":"2024-03-11T13:19:12.679935Z","shell.execute_reply.started":"2024-03-11T13:19:12.661808Z","shell.execute_reply":"2024-03-11T13:19:12.679222Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"                                                    Öncül  \\\n500000  Konya'da, kız kardeşi E.B.'ye (16) cinsel isti...   \n500001  MHP Eyüp eski İlçe Başkanı Köksal Kaçmaz'ın vu...   \n500002  MHP Eyüp eski İlçe Başkanı Köksal Kaçmaz'ın vu...   \n500003  Merkez Bankası’nın faizi yüzde 20’ye çıkarması...   \n500004  Merkez Bankası’nın faizi yüzde 20’ye çıkarması...   \n...                                                   ...   \n500413   Cumhurbaşkanı Erdoğan: \"Gözümüzü 2053'e diktik.\"   \n500414   Cumhurbaşkanı Erdoğan: \"Gözümüzü 2053'e diktik.\"   \n500415   Cumhurbaşkanı Erdoğan: \"Gözümüzü 2053'e diktik.\"   \n500416   Cumhurbaşkanı Erdoğan: \"Gözümüzü 2053'e diktik.\"   \n500417   Cumhurbaşkanı Erdoğan: \"Gözümüzü 2053'e diktik.\"   \n\n                                                  hipotez   etiket  \n500000  Konya'da, kız kardeşi E.B.'ye (16) cinsel isti...        0  \n500001  Konya'da, kız kardeşi E.B.'ye (16) cinsel isti...        2  \n500002  MHP Eyüp eski İlçe Başkanı Köksal Kaçmaz'ın vu...        0  \n500003  Konya'da, kız kardeşi E.B.'ye (16) cinsel isti...        2  \n500004  MHP Eyüp eski İlçe Başkanı Köksal Kaçmaz'ın vu...        2  \n...                                                   ...      ...  \n500413  Yozgat'ta 12 kişinin yaşamını yitirdiği, 18 ki...        2  \n500414  Cumhurbaşkanı Erdoğan: \"Hayat pahalılığı sorun...        2  \n500415  Cumhurbaşkanı Erdoğan: \"Hayat pahalılığı sorun...        2  \n500416  #SONDAKİKA | Türkiye, Yunanistan'a yangınlarla...        2  \n500417  Cumhurbaşkanı Erdoğan: \\n\\n“2023 vizyonumuzun ...        0  \n\n[418 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Öncül</th>\n      <th>hipotez</th>\n      <th>etiket</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>500000</th>\n      <td>Konya'da, kız kardeşi E.B.'ye (16) cinsel isti...</td>\n      <td>Konya'da, kız kardeşi E.B.'ye (16) cinsel isti...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>500001</th>\n      <td>MHP Eyüp eski İlçe Başkanı Köksal Kaçmaz'ın vu...</td>\n      <td>Konya'da, kız kardeşi E.B.'ye (16) cinsel isti...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>500002</th>\n      <td>MHP Eyüp eski İlçe Başkanı Köksal Kaçmaz'ın vu...</td>\n      <td>MHP Eyüp eski İlçe Başkanı Köksal Kaçmaz'ın vu...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>500003</th>\n      <td>Merkez Bankası’nın faizi yüzde 20’ye çıkarması...</td>\n      <td>Konya'da, kız kardeşi E.B.'ye (16) cinsel isti...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>500004</th>\n      <td>Merkez Bankası’nın faizi yüzde 20’ye çıkarması...</td>\n      <td>MHP Eyüp eski İlçe Başkanı Köksal Kaçmaz'ın vu...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>500413</th>\n      <td>Cumhurbaşkanı Erdoğan: \"Gözümüzü 2053'e diktik.\"</td>\n      <td>Yozgat'ta 12 kişinin yaşamını yitirdiği, 18 ki...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>500414</th>\n      <td>Cumhurbaşkanı Erdoğan: \"Gözümüzü 2053'e diktik.\"</td>\n      <td>Cumhurbaşkanı Erdoğan: \"Hayat pahalılığı sorun...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>500415</th>\n      <td>Cumhurbaşkanı Erdoğan: \"Gözümüzü 2053'e diktik.\"</td>\n      <td>Cumhurbaşkanı Erdoğan: \"Hayat pahalılığı sorun...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>500416</th>\n      <td>Cumhurbaşkanı Erdoğan: \"Gözümüzü 2053'e diktik.\"</td>\n      <td>#SONDAKİKA | Türkiye, Yunanistan'a yangınlarla...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>500417</th>\n      <td>Cumhurbaşkanı Erdoğan: \"Gözümüzü 2053'e diktik.\"</td>\n      <td>Cumhurbaşkanı Erdoğan: \\n\\n“2023 vizyonumuzun ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>418 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import re\n\ndef process_text(text):\n    # Noktalama işaretlerini kaldırmak için regex kullanıyoruz\n\n    no_punct_spaces_text = re.sub(r'[^\\w\\s]', ' ', str(text))\n    \n    # Ardışık boşlukları tek bir boşlukla değiştiriyoruz\n    final_text = re.sub(r'\\s+', ' ', no_punct_spaces_text).strip()\n    \n    return final_text\n\n# DataFrame'deki her metin için işlemleri uyguluyoruz\ndata['Öncül'] = data['Öncül'].apply(process_text)\ndata[' hipotez'] = data[' hipotez'].apply(process_text)","metadata":{"_uuid":"74c818c2-c5cf-47fa-864e-c054ca92a27a","_cell_guid":"900d8083-ab1f-4853-b32b-a057ac194c49","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-11T13:19:12.680940Z","iopub.execute_input":"2024-03-11T13:19:12.681203Z","iopub.status.idle":"2024-03-11T13:19:20.367784Z","shell.execute_reply.started":"2024-03-11T13:19:12.681180Z","shell.execute_reply":"2024-03-11T13:19:20.366879Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"display(data[500000:])","metadata":{"_uuid":"fe47a38f-0fea-4714-8616-a772302b03ca","_cell_guid":"3497fee0-b7e8-4c80-8613-21f73e0c6cc3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-11T13:19:20.370461Z","iopub.execute_input":"2024-03-11T13:19:20.370725Z","iopub.status.idle":"2024-03-11T13:19:20.382526Z","shell.execute_reply.started":"2024-03-11T13:19:20.370703Z","shell.execute_reply":"2024-03-11T13:19:20.381831Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"                                                    Öncül  \\\n500000  Konya da kız kardeşi E B ye 16 cinsel istismar...   \n500001  MHP Eyüp eski İlçe Başkanı Köksal Kaçmaz ın vu...   \n500002  MHP Eyüp eski İlçe Başkanı Köksal Kaçmaz ın vu...   \n500003  Merkez Bankası nın faizi yüzde 20 ye çıkarması...   \n500004  Merkez Bankası nın faizi yüzde 20 ye çıkarması...   \n...                                                   ...   \n500413       Cumhurbaşkanı Erdoğan Gözümüzü 2053 e diktik   \n500414       Cumhurbaşkanı Erdoğan Gözümüzü 2053 e diktik   \n500415       Cumhurbaşkanı Erdoğan Gözümüzü 2053 e diktik   \n500416       Cumhurbaşkanı Erdoğan Gözümüzü 2053 e diktik   \n500417       Cumhurbaşkanı Erdoğan Gözümüzü 2053 e diktik   \n\n                                                  hipotez   etiket  \n500000  Konya da kız kardeşi E B ye 16 cinsel istismar...        0  \n500001  Konya da kız kardeşi E B ye 16 cinsel istismar...        2  \n500002  MHP Eyüp eski İlçe Başkanı Köksal Kaçmaz ın vu...        0  \n500003  Konya da kız kardeşi E B ye 16 cinsel istismar...        2  \n500004  MHP Eyüp eski İlçe Başkanı Köksal Kaçmaz ın vu...        2  \n...                                                   ...      ...  \n500413  Yozgat ta 12 kişinin yaşamını yitirdiği 18 kiş...        2  \n500414  Cumhurbaşkanı Erdoğan Hayat pahalılığı sorunun...        2  \n500415  Cumhurbaşkanı Erdoğan Hayat pahalılığı sorunun...        2  \n500416  SONDAKİKA Türkiye Yunanistan a yangınlarla müc...        2  \n500417  Cumhurbaşkanı Erdoğan 2023 vizyonumuzun çoğunu...        0  \n\n[418 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Öncül</th>\n      <th>hipotez</th>\n      <th>etiket</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>500000</th>\n      <td>Konya da kız kardeşi E B ye 16 cinsel istismar...</td>\n      <td>Konya da kız kardeşi E B ye 16 cinsel istismar...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>500001</th>\n      <td>MHP Eyüp eski İlçe Başkanı Köksal Kaçmaz ın vu...</td>\n      <td>Konya da kız kardeşi E B ye 16 cinsel istismar...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>500002</th>\n      <td>MHP Eyüp eski İlçe Başkanı Köksal Kaçmaz ın vu...</td>\n      <td>MHP Eyüp eski İlçe Başkanı Köksal Kaçmaz ın vu...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>500003</th>\n      <td>Merkez Bankası nın faizi yüzde 20 ye çıkarması...</td>\n      <td>Konya da kız kardeşi E B ye 16 cinsel istismar...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>500004</th>\n      <td>Merkez Bankası nın faizi yüzde 20 ye çıkarması...</td>\n      <td>MHP Eyüp eski İlçe Başkanı Köksal Kaçmaz ın vu...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>500413</th>\n      <td>Cumhurbaşkanı Erdoğan Gözümüzü 2053 e diktik</td>\n      <td>Yozgat ta 12 kişinin yaşamını yitirdiği 18 kiş...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>500414</th>\n      <td>Cumhurbaşkanı Erdoğan Gözümüzü 2053 e diktik</td>\n      <td>Cumhurbaşkanı Erdoğan Hayat pahalılığı sorunun...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>500415</th>\n      <td>Cumhurbaşkanı Erdoğan Gözümüzü 2053 e diktik</td>\n      <td>Cumhurbaşkanı Erdoğan Hayat pahalılığı sorunun...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>500416</th>\n      <td>Cumhurbaşkanı Erdoğan Gözümüzü 2053 e diktik</td>\n      <td>SONDAKİKA Türkiye Yunanistan a yangınlarla müc...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>500417</th>\n      <td>Cumhurbaşkanı Erdoğan Gözümüzü 2053 e diktik</td>\n      <td>Cumhurbaşkanı Erdoğan 2023 vizyonumuzun çoğunu...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>418 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df = data","metadata":{"_uuid":"89baa91e-36b9-4ace-9144-5e43c082d015","_cell_guid":"77f2b0a5-c6a2-4223-9987-3414833154a0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-11T13:19:20.383503Z","iopub.execute_input":"2024-03-11T13:19:20.383813Z","iopub.status.idle":"2024-03-11T13:19:20.392834Z","shell.execute_reply.started":"2024-03-11T13:19:20.383787Z","shell.execute_reply":"2024-03-11T13:19:20.392017Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(train_df[\" etiket\"].value_counts())","metadata":{"_uuid":"4f7399dc-847a-4c52-841b-a8ba1b2111a0","_cell_guid":"7fb97108-86ee-49c9-aa75-bbbf63fd4e15","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-11T13:19:20.393891Z","iopub.execute_input":"2024-03-11T13:19:20.394251Z","iopub.status.idle":"2024-03-11T13:19:20.407413Z","shell.execute_reply.started":"2024-03-11T13:19:20.394224Z","shell.execute_reply":"2024-03-11T13:19:20.406680Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":" etiket\n 2    166905\n 0    166739\n 1    166093\n-1       681\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df = (\n    train_df[train_df[\" etiket\"] != -1]\n    .sample(frac=1.0, random_state=42)\n    .reset_index(drop=True)\n)","metadata":{"_uuid":"56f6dcb6-03ec-40e2-9e64-bc6b69fc8795","_cell_guid":"b72ea218-e02d-4a53-ae17-1b34d375ad58","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-11T13:19:20.408345Z","iopub.execute_input":"2024-03-11T13:19:20.408666Z","iopub.status.idle":"2024-03-11T13:19:20.794387Z","shell.execute_reply.started":"2024-03-11T13:19:20.408625Z","shell.execute_reply":"2024-03-11T13:19:20.793385Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(train_df[\" etiket\"].value_counts())","metadata":{"_uuid":"03e2aa47-62a2-413a-a313-98a39c1c4416","_cell_guid":"4b2ede3d-9a6c-4077-8e06-5b7cfd2647ca","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-11T13:19:20.795574Z","iopub.execute_input":"2024-03-11T13:19:20.795909Z","iopub.status.idle":"2024-03-11T13:19:20.805707Z","shell.execute_reply.started":"2024-03-11T13:19:20.795882Z","shell.execute_reply":"2024-03-11T13:19:20.804906Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":" etiket\n2    166905\n0    166739\n1    166093\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"y_train = tf.keras.utils.to_categorical(train_df[\" etiket\"], num_classes=3)","metadata":{"_uuid":"afe9fbb7-0a0f-4b6d-b2ed-18aaf67096e0","_cell_guid":"f0bb6669-c621-40a3-8af7-86b15bd4e1c6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-11T13:19:20.806721Z","iopub.execute_input":"2024-03-11T13:19:20.807272Z","iopub.status.idle":"2024-03-11T13:19:20.831759Z","shell.execute_reply.started":"2024-03-11T13:19:20.807245Z","shell.execute_reply":"2024-03-11T13:19:20.830949Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class BertSemanticDataGenerator(tf.keras.utils.Sequence):\n    \"\"\"Generates batches of data.\n\n    Args:\n        sentence_pairs: Array of premise and hypothesis input sentences.\n        labels: Array of labels.\n        batch_size: Integer batch size.\n        shuffle: boolean, whether to shuffle the data.\n        include_targets: boolean, whether to incude the labels.\n\n    Returns:\n        Tuples `([input_ids, attention_mask, `token_type_ids], labels)`\n        (or just `[input_ids, attention_mask, `token_type_ids]`\n         if `include_targets=False`)\n    \"\"\"\n\n    def __init__(\n        self,\n        sentence_pairs,\n        labels,\n        batch_size=batch_size,\n        shuffle=True,\n        include_targets=True,\n    ):\n        self.sentence_pairs = sentence_pairs\n        self.labels = labels\n        self.shuffle = shuffle\n        self.batch_size = batch_size\n        self.include_targets = include_targets\n        # Load our BERT Tokenizer to encode the text.\n        # We will use base-base-uncased pretrained model.\n        self.tokenizer = transformers.AutoTokenizer.from_pretrained(\n            \"dbmdz/bert-base-turkish-128k-uncased\", do_lower_case=True\n        )\n        self.indexes = np.arange(len(self.sentence_pairs))\n        self.on_epoch_end()\n\n    def __len__(self):\n        # Denotes the number of batches per epoch.\n        return len(self.sentence_pairs) // self.batch_size\n\n    def __getitem__(self, idx):\n        # Retrieves the batch of index.\n        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n        sentence_pairs = self.sentence_pairs[indexes]\n\n        # With BERT tokenizer's batch_encode_plus batch of both the sentences are\n        # encoded together and separated by [SEP] token.\n        encoded = self.tokenizer.batch_encode_plus(\n            sentence_pairs.tolist(),\n            add_special_tokens=True,\n            max_length=max_length,\n            return_attention_mask=True,\n            return_token_type_ids=True,\n            pad_to_max_length=True,\n            return_tensors=\"tf\",\n        )\n\n        # Convert batch of encoded features to numpy array.\n        input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n        attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n        token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n\n        # Set to true if data generator is used for training/validation.\n        if self.include_targets:\n            labels = np.array(self.labels[indexes], dtype=\"int32\")\n            return [input_ids, attention_masks, token_type_ids], labels\n        else:\n            return [input_ids, attention_masks, token_type_ids]\n\n    def on_epoch_end(self):\n        # Shuffle indexes after each epoch if shuffle is set to True.\n        if self.shuffle:\n            np.random.RandomState(42).shuffle(self.indexes)","metadata":{"_uuid":"954890d0-4c46-481c-b1c5-f7d319d804ed","_cell_guid":"b8f58ea8-2304-4a2b-a2e6-33c90f5a4316","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-11T13:19:20.833013Z","iopub.execute_input":"2024-03-11T13:19:20.833288Z","iopub.status.idle":"2024-03-11T13:19:20.848997Z","shell.execute_reply.started":"2024-03-11T13:19:20.833264Z","shell.execute_reply":"2024-03-11T13:19:20.848165Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"67ab00b4-713f-499d-a352-6a5006636cda","_cell_guid":"dbd6fc76-68e6-4b64-b80e-7d24ad9022ae","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\nstrategy = tf.distribute.TPUStrategy(tpu)\n\nwith strategy.scope():\n    # Encoded token ids from BERT tokenizer.\n    input_ids = tf.keras.layers.Input(\n        shape=(max_length,), dtype=tf.int32, name=\"input_ids\"\n    )\n    # Attention masks indicates to the model which tokens should be attended to.\n    attention_masks = tf.keras.layers.Input(\n        shape=(max_length,), dtype=tf.int32, name=\"attention_masks\"\n    )\n    # Token type ids are binary masks identifying different sequences in the model.\n    token_type_ids = tf.keras.layers.Input(\n        shape=(max_length,), dtype=tf.int32, name=\"token_type_ids\"\n    )\n    # Loading pretrained BERT model.\n    bert_model = transformers.TFAutoModel.from_pretrained(\"dbmdz/bert-base-turkish-128k-uncased\")\n    # Freeze the BERT model to reuse the pretrained features without modifying them.\n    bert_model.trainable = False\n\n    bert_output = bert_model(\n        input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n    )\n    sequence_output = bert_output.last_hidden_state\n    pooled_output = bert_output.pooler_output\n    # Add trainable layers on top of frozen layers to adapt the pretrained features on the new data.\n    bi_lstm = tf.keras.layers.Bidirectional(\n        tf.keras.layers.LSTM(256, return_sequences=True)\n    )(sequence_output)\n    # Applying hybrid pooling approach to bi_lstm sequence output.\n    avg_pool = tf.keras.layers.GlobalAveragePooling1D()(bi_lstm)\n    max_pool = tf.keras.layers.GlobalMaxPooling1D()(bi_lstm)\n    concat = tf.keras.layers.concatenate([avg_pool, max_pool])\n    dropout = tf.keras.layers.Dropout(0.3)(concat)\n    x = tf.keras.layers.Dense(128, activation=\"relu\")(dropout)\n    dropout = tf.keras.layers.Dropout(0.3)(x)\n    output = tf.keras.layers.Dense(3, activation=\"softmax\")(dropout)\n    model = tf.keras.models.Model(\n        inputs=[input_ids, attention_masks, token_type_ids], outputs=output\n    )\n\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(),\n        steps_per_execution = 50,\n        loss=\"categorical_crossentropy\",\n        metrics=[\"acc\"],\n    )\n\n\nprint(f\"Strategy: {strategy}\")\nmodel.summary()","metadata":{"_uuid":"78166f1f-3b9f-48e2-9344-5da46a13fe92","_cell_guid":"7092492d-833b-42ea-93c9-5c42f25be2f0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-11T13:19:20.849995Z","iopub.execute_input":"2024-03-11T13:19:20.850242Z","iopub.status.idle":"2024-03-11T13:19:53.966063Z","shell.execute_reply.started":"2024-03-11T13:19:20.850219Z","shell.execute_reply":"2024-03-11T13:19:53.964955Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\nINFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"Some layers from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the layers of TFBertModel were initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Strategy: <tensorflow.python.distribute.tpu_strategy.TPUStrategyV2 object at 0x79eebf80ce80>\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_ids (InputLayer)         [(None, 128)]        0           []                               \n                                                                                                  \n attention_masks (InputLayer)   [(None, 128)]        0           []                               \n                                                                                                  \n token_type_ids (InputLayer)    [(None, 128)]        0           []                               \n                                                                                                  \n tf_bert_model (TFBertModel)    TFBaseModelOutputWi  184345344   ['input_ids[0][0]',              \n                                thPoolingAndCrossAt               'attention_masks[0][0]',        \n                                tentions(last_hidde               'token_type_ids[0][0]']         \n                                n_state=(None, 128,                                               \n                                 768),                                                            \n                                 pooler_output=(Non                                               \n                                e, 768),                                                          \n                                 past_key_values=No                                               \n                                ne, hidden_states=N                                               \n                                one, attentions=Non                                               \n                                e, cross_attentions                                               \n                                =None)                                                            \n                                                                                                  \n bidirectional (Bidirectional)  (None, 128, 512)     2099200     ['tf_bert_model[0][0]']          \n                                                                                                  \n global_average_pooling1d (Glob  (None, 512)         0           ['bidirectional[0][0]']          \n alAveragePooling1D)                                                                              \n                                                                                                  \n global_max_pooling1d (GlobalMa  (None, 512)         0           ['bidirectional[0][0]']          \n xPooling1D)                                                                                      \n                                                                                                  \n concatenate (Concatenate)      (None, 1024)         0           ['global_average_pooling1d[0][0]'\n                                                                 , 'global_max_pooling1d[0][0]']  \n                                                                                                  \n dropout_37 (Dropout)           (None, 1024)         0           ['concatenate[0][0]']            \n                                                                                                  \n dense (Dense)                  (None, 128)          131200      ['dropout_37[0][0]']             \n                                                                                                  \n dropout_38 (Dropout)           (None, 128)          0           ['dense[0][0]']                  \n                                                                                                  \n dense_1 (Dense)                (None, 3)            387         ['dropout_38[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 186,576,131\nTrainable params: 2,230,787\nNon-trainable params: 184,345,344\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\ntrain_data = BertSemanticDataGenerator(\n    train_df[[\"Öncül\", \" hipotez\"]].values.astype(\"str\"),\n    y_train,\n    batch_size=batch_size,\n    shuffle=True,\n)","metadata":{"_uuid":"4da8e0d3-42c3-400d-96fa-ad94e023fb13","_cell_guid":"ae97e120-b446-4cb9-83d7-505161675dcf","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-11T13:19:53.967389Z","iopub.execute_input":"2024-03-11T13:19:53.967843Z","iopub.status.idle":"2024-03-11T13:19:56.188424Z","shell.execute_reply.started":"2024-03-11T13:19:53.967812Z","shell.execute_reply":"2024-03-11T13:19:56.187133Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_data,\n    epochs=0,\n    steps_per_epoch=steps_per_epoch,\n)","metadata":{"_uuid":"f543f29d-13ac-4fcc-a7d6-8f8eac86b385","_cell_guid":"54e91f76-a373-4a3c-942f-5a2e171a1c5b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-11T13:19:56.189799Z","iopub.execute_input":"2024-03-11T13:19:56.190157Z","iopub.status.idle":"2024-03-11T13:19:56.787785Z","shell.execute_reply.started":"2024-03-11T13:19:56.190127Z","shell.execute_reply":"2024-03-11T13:19:56.786524Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/usr/local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2645: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit(\n    train_data,\n    epochs=0,\n    steps_per_epoch=steps_per_epoch,\n)","metadata":{"_uuid":"41d2d3b4-1670-4fea-a38c-38897583695f","_cell_guid":"32cc4c2d-e00e-4b72-bed4-634174a7a1e3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-11T13:19:56.789455Z","iopub.execute_input":"2024-03-11T13:19:56.789761Z","iopub.status.idle":"2024-03-11T13:19:57.263519Z","shell.execute_reply.started":"2024-03-11T13:19:56.789733Z","shell.execute_reply":"2024-03-11T13:19:57.262293Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x79eea8bc1a30>"},"metadata":{}}]},{"cell_type":"code","source":"import keras\n\nwith strategy.scope():\n    model = tf.keras.models.load_model('/kaggle/input/keras-80acc/keras.model', custom_objects={\"TFBertModel\": transformers.TFAutoModel.from_pretrained(\"dbmdz/bert-base-turkish-128k-uncased\")})\n    \n    for l in model.layers:\n        if l.name == \"tf_bert_model\":\n            l.trainable = True\n        print(l.name, l.trainable)    \n        \n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(1e-5),\n        steps_per_execution = 50,\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"],\n    )\n\n    model.summary()\n    \nmodel.fit(\n    train_data,\n    epochs=0,\n\n)","metadata":{"_uuid":"1fa737c3-ee83-4c90-9239-56946f3db9b5","_cell_guid":"2253ce18-ea67-4fba-9edf-692908b9c00e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-11T13:25:01.377911Z","iopub.execute_input":"2024-03-11T13:25:01.378917Z","iopub.status.idle":"2024-03-11T13:25:42.839698Z","shell.execute_reply.started":"2024-03-11T13:25:01.378870Z","shell.execute_reply":"2024-03-11T13:25:42.838575Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Some layers from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the layers of TFBertModel were initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"input_ids True\nattention_masks True\ntoken_type_ids True\ntf_bert_model True\nbidirectional True\nglobal_average_pooling1d True\nglobal_max_pooling1d True\nconcatenate True\ndropout_37 True\ndense True\ndropout_38 True\ndense_1 True\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_ids (InputLayer)         [(None, 128)]        0           []                               \n                                                                                                  \n attention_masks (InputLayer)   [(None, 128)]        0           []                               \n                                                                                                  \n token_type_ids (InputLayer)    [(None, 128)]        0           []                               \n                                                                                                  \n tf_bert_model (TFBertModel)    TFBaseModelOutputWi  184345344   ['input_ids[0][0]',              \n                                thPoolingAndCrossAt               'attention_masks[0][0]',        \n                                tentions(last_hidde               'token_type_ids[0][0]']         \n                                n_state=(None, 128,                                               \n                                 768),                                                            \n                                 pooler_output=(Non                                               \n                                e, 768),                                                          \n                                 past_key_values=No                                               \n                                ne, hidden_states=N                                               \n                                one, attentions=Non                                               \n                                e, cross_attentions                                               \n                                =None)                                                            \n                                                                                                  \n bidirectional (Bidirectional)  (None, 128, 512)     2099200     ['tf_bert_model[0][0]']          \n                                                                                                  \n global_average_pooling1d (Glob  (None, 512)         0           ['bidirectional[0][0]']          \n alAveragePooling1D)                                                                              \n                                                                                                  \n global_max_pooling1d (GlobalMa  (None, 512)         0           ['bidirectional[0][0]']          \n xPooling1D)                                                                                      \n                                                                                                  \n concatenate (Concatenate)      (None, 1024)         0           ['global_average_pooling1d[0][0]'\n                                                                 , 'global_max_pooling1d[0][0]']  \n                                                                                                  \n dropout_37 (Dropout)           (None, 1024)         0           ['concatenate[0][0]']            \n                                                                                                  \n dense (Dense)                  (None, 128)          131200      ['dropout_37[0][0]']             \n                                                                                                  \n dropout_38 (Dropout)           (None, 128)          0           ['dense[0][0]']                  \n                                                                                                  \n dense_1 (Dense)                (None, 3)            387         ['dropout_38[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 186,576,131\nTrainable params: 186,576,131\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2645: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x79e2a1247730>"},"metadata":{}}]},{"cell_type":"markdown","source":"<a href=\"/kaggle/working/keras.model\"> Download File </a>","metadata":{"_uuid":"32b5791d-ef7c-4a80-9d9e-b6688caa309d","_cell_guid":"c58e3afd-c19a-426b-8bcb-b52381d7db9b","trusted":true}},{"cell_type":"code","source":"def check_similarity(sentence1, sentence2):\n    sentence_pairs = np.array([[str(sentence1), str(sentence2)]])\n    test_data = BertSemanticDataGenerator(\n        sentence_pairs, labels=None, batch_size=1, shuffle=False, include_targets=False,\n    )\n    proba = model.predict(test_data[0])[0]\n    idx = np.argmax(proba)\n    proba = f\"{proba[idx]: .2f}%\"\n    pred = idx\n    return pred, proba","metadata":{"_uuid":"a726ce35-8dc8-4ec1-a3d1-f04af9dde551","_cell_guid":"c1cf4fd1-0391-4abe-b097-669084919f58","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-11T13:26:14.919512Z","iopub.execute_input":"2024-03-11T13:26:14.919937Z","iopub.status.idle":"2024-03-11T13:26:14.926227Z","shell.execute_reply.started":"2024-03-11T13:26:14.919904Z","shell.execute_reply":"2024-03-11T13:26:14.925220Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model.save(\"keras.model\")","metadata":{"_uuid":"84b86761-03ae-414a-a35c-e495d5d3d1a8","_cell_guid":"cdf23037-f0c1-4d67-a953-d7bf85c5d5d6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-11T13:24:53.344314Z","iopub.status.idle":"2024-03-11T13:24:53.344617Z","shell.execute_reply.started":"2024-03-11T13:24:53.344469Z","shell.execute_reply":"2024-03-11T13:24:53.344484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence1 = \"İstanbul’da trafik kurallarına uymayan ve agresif tavırlar sergileyen taksiciye arka arkaya 2 ceza kesildi..\"\nsentence2 = \"Şehit Eren Bülbül'ün annesi sezonun ilk maçında Trabzonspor stadyumuna geldi\"\ncheck_similarity(sentence1, sentence2)","metadata":{"_uuid":"1e0b23cf-251c-4d69-9550-496f74c79c80","_cell_guid":"b8f551b3-ba5e-4131-83c5-87c199ebd87a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-11T13:26:20.393594Z","iopub.execute_input":"2024-03-11T13:26:20.394034Z","iopub.status.idle":"2024-03-11T13:26:37.909548Z","shell.execute_reply.started":"2024-03-11T13:26:20.393995Z","shell.execute_reply":"2024-03-11T13:26:37.908378Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n2024-03-11 13:26:30.338949: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n2024-03-11 13:26:31.140156: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 17s 17s/step\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"(2, ' 0.98%')"},"metadata":{}}]}]}